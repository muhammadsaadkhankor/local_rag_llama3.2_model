# PDF RAG Chat Application

A modern React + FastAPI application for chatting with your PDFs using Llama 3.2.

## ğŸ—ï¸ Project Structure

```
custom_model/
â”œâ”€â”€ backend/           # FastAPI server
â”‚   â”œâ”€â”€ main.py       # API endpoints
â”‚   â”œâ”€â”€ simple_rag.py # RAG logic
â”‚   â””â”€â”€ pdfs/         # Your PDF files
â”œâ”€â”€ frontend/         # React TypeScript app
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.tsx   # Main chat component
â”‚       â””â”€â”€ App.css   # Styles
â””â”€â”€ start.sh          # Start both servers
```

## ğŸš€ Quick Start

1. **Install backend dependencies:**
```bash
cd backend
pip install -r api_requirements.txt
```

2. **Install frontend dependencies:**
```bash
cd frontend
npm install
```

3. **Add your PDFs:**
```bash
# Copy your PDF files to backend/pdfs/
cp /path/to/your/file.pdf backend/pdfs/
```

4. **Start the application:**
```bash
./start.sh
```

5. **Open your browser:**
   - Frontend: http://localhost:3000
   - API docs: http://localhost:8000/docs

## âœ¨ Features

- ğŸ¨ **Modern React UI** - Clean, responsive chat interface
- âš¡ **Fast API** - Cached embeddings, no PDF reloading
- ğŸ§  **Smart RAG** - Uses Llama 3.2 with context retrieval
- ğŸ“± **Mobile Friendly** - Works on all devices
- ğŸ”„ **Real-time Status** - Shows PDF count and readiness

## ğŸ› ï¸ Manual Start

**Backend only:**
```bash
cd backend
python main.py
```

**Frontend only:**
```bash
cd frontend
npm start
```

## ğŸ“ API Endpoints

- `GET /status` - Check system status
- `POST /query` - Send questions to RAG system

The backend loads PDFs once and keeps them in memory for fast responses!# local_llama_rag_model
# local_rag_llama3.2_model
